# AI_GAN_GENERATION
# Text_to_image_generation
Our methodology involves the use of Generative Adversarial Networks (GANs) to generate images from text descriptions. We utilize GloVe embeddings to represent words as dense vectors and capture semantic relationships. The model consists of a Text Encoder, Image Generator, and Image Discriminator. The training protocol involves adversarial training, where the generator and discriminator models are trained simultaneously. The objective is for the generator to create realistic images while the discriminator distinguishes between real and generated images. We use binary cross-entropy as the loss function. This methodology enables us to generate high-quality images from text descriptions.

